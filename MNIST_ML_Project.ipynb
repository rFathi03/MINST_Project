{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOHGOex26g3f"
      },
      "source": [
        "## MNIST ML Project:\n",
        "**Project Description:**\n",
        "\n",
        "It is a dataset of handwritten numbers from\n",
        "0 to 9. MNIST has a training set of 60,000 examples, and a test set of 10,000\n",
        "examples. It can be downloaded from: http://yann.lecun.com/exdb/mnist/\n",
        "K Nearest Neighbors (KNN) is a classifier that finds the class of the test sample\n",
        "based on the distance of it from the training samples. It finds the K training\n",
        "samples with smallest distance to the test sample. The dominant class in the K\n",
        "points is then selected as the test point class.\n",
        "\n",
        "\n",
        "**Team Members:**\n",
        "\n",
        "Roaa Fathi Nada\n",
        "\n",
        "Selsabeel Asim Ali Elbagir\n",
        "\n",
        "Basma Mahmoud Hashem\n",
        "\n",
        "Howida Adel Abd El-Halim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTrLTkoB5NOe"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTo7RnqPn6XB"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import exposure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxU0Qeav527-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959c0eb7-af7e-4193-ef22-a1a2f3ed5d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70jyN9bm5yIv"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIastbva571-",
        "outputId": "02320dc0-d143-41b2-9c36-c03e4756b5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (48000, 28, 28) (48000,)\n",
            "Validation set shape: (12000, 28, 28) (12000,)\n",
            "Testing set shape: (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of each set\n",
        "print(\"Training set shape:\", x_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", x_val.shape, y_val.shape)\n",
        "print(\"Testing set shape:\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vuFZJpLna4k"
      },
      "source": [
        "# Applying HOG Features to the images (sklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmjGOW9Fm-p3"
      },
      "source": [
        "*  HOG focuses on the structure of the object. It extracts the information of the edges magnitude as well as the orientation of the edges.\n",
        "*   It uses a detection window of 64x128 pixels, so the image is first converted into (64, 128) shape.\n",
        "*   The image is then further divided into small parts, and then the gradient and orientation of each part is calculated. It is divided into 8x16 cells into blocks with 50% overlap, so there are going to be 7x15 = 105 blocks in total, and each block consists of 2x2 cells with 8x8 pixels.\n",
        "*   We take the 64 gradient vectors of each block (8x8 pixel cell) and put them into a 9-bin histogram.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJVSdJUSrTiR"
      },
      "outputs": [],
      "source": [
        "# Function to compute HOG features for a given image\n",
        "def compute_hog_features(image):\n",
        "    # Image resized to fit the detection window of 64x128 pixels\n",
        "    resized_img = resize(image, (128, 64))\n",
        "\n",
        "    # Compute HOG features using sk-learn built in function\n",
        "    features = hog(resized_img, block_norm='L2-Hys', pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n",
        "    #each block consists of 2x2 cells, and every cell has 8x8 pixels\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcOP6Pq0s2gO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29387a59-ff35-4e77-a4b7-5e99100b0c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG Features shape for the first image in the training set: (3780,)\n"
          ]
        }
      ],
      "source": [
        "# Apply HOG features to the entire training set\n",
        "hog_features_train = [compute_hog_features(img) for img in x_train]\n",
        "\n",
        "# Apply HOG features to the entire validation set\n",
        "hog_features_val = [compute_hog_features(img) for img in x_val]\n",
        "\n",
        "# Apply HOG features to the entire testing set\n",
        "hog_features_test = [compute_hog_features(img) for img in x_test]\n",
        "\n",
        "# Display the shape of the HOG features for the first image in the training set\n",
        "print(\"HOG Features shape for the first image in the training set:\", hog_features_train[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1WR6WRwtqzE"
      },
      "source": [
        "# KNN with 'K' as a parameter and Euclidian distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9tTCM7_5qC7"
      },
      "source": [
        "(For my teammates to see ofc)\n",
        "This link is nice for explaining what KNN does, in code:\n",
        "https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
        "\n",
        "Step 1: Calculate Euclidean Distance.\n",
        "\n",
        "Step 2: Get Nearest Neighbors.\n",
        "\n",
        "Step 3: Make Predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPRDSvk242hW"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXNo3pmPt0CM"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(hog_features_train)\n",
        "X_val = np.array(hog_features_val)\n",
        "X_test = np.array(hog_features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTlVksSLSuvb"
      },
      "outputs": [],
      "source": [
        "# Flatten the labels\n",
        "#y_train_flat = y_train.flatten()\n",
        "#y_val_flat = y_val.flatten()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S4SiAOOTEP3"
      },
      "source": [
        "flatten the arrays to ensure each element corresponds to one label, which simplifies the proccess of classification for the built in KNN function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlmdrw-MSzPC"
      },
      "outputs": [],
      "source": [
        "# Function to train and evaluate KNN classifier\n",
        "def calculate_knn_metrics(k):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, metric = 'euclidean')\n",
        "    ## uses euclidean metric for our KNN classifier\n",
        "\n",
        "    # Train the classifier\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    predictions = knn.predict(X_val)\n",
        "\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    print(f\"Accuracy for k={k}: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Calculate precision\n",
        "    precision = precision_score(y_val, predictions, average='weighted')\n",
        "\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(y_val, predictions, average='weighted')\n",
        "    return precision, f1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGbkdCACS1Ll",
        "outputId": "546c7416-4519-4a2d-e023-e10f9a98d030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k=1: 97.82%\n",
            "Precision for KNN: 0.98\n",
            "F1 Score for KNN: 0.98\n",
            "====================================\n",
            "Accuracy for k=3: 97.65%\n",
            "Precision for KNN: 0.98\n",
            "F1 Score for KNN: 0.98\n",
            "====================================\n",
            "Accuracy for k=5: 97.58%\n",
            "Precision for KNN: 0.98\n",
            "F1 Score for KNN: 0.98\n",
            "====================================\n"
          ]
        }
      ],
      "source": [
        "# Test different values of K\n",
        "for k in [1, 3, 5]:\n",
        "  precision_knn, f1_knn = calculate_knn_metrics(k)\n",
        "  print(f\"Precision for KNN: {precision_knn:.2f}\")\n",
        "  print(f\"F1 Score for KNN: {f1_knn:.2f}\")\n",
        "  print(\"====================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muou7zvjt0kT"
      },
      "source": [
        "# Implement SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj57pNuzuCrT"
      },
      "outputs": [],
      "source": [
        "def calculate_svm_metrics(X_train, y_train, X_val, y_val, C=1.0, degree=3):\n",
        "  # Create a linear SVM classifier\n",
        "  svm = SVC(kernel='linear', C=C, degree=degree)\n",
        "\n",
        "  # Train the classifier\n",
        "  svm.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions on the validation set\n",
        "  predictions = svm.predict(X_val)\n",
        "\n",
        "  # Evaluate accuracy\n",
        "  accuracy = accuracy_score(y_val, predictions)\n",
        "  print(f\"Accuracy for SVM: {accuracy * 100:.2f}%\")\n",
        "\n",
        "  # Calculate precision\n",
        "  precision = precision_score(y_val, predictions, average='weighted')\n",
        "\n",
        "  # Calculate F1 score\n",
        "  f1 = f1_score(y_val, predictions, average='weighted')\n",
        "\n",
        "  return precision, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM with Different Hyper Parameters"
      ],
      "metadata": {
        "id": "4vGdWAdEGOf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape X_train\n",
        "#X_train_flat = X_train.reshape(X_train.shape[0], -1)"
      ],
      "metadata": {
        "id": "A8j_QzeCUzPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Smaller Regularization Parameter (C) ===>\n",
        "precision_svm_1, f1_svm_1 = calculate_svm_metrics(X_train, y_train, X_val, y_val, C=0.8, degree=3)\n",
        "print(f\"Precision for SVM (C=0.8): {precision_svm_1:.2f}\")\n",
        "print(f\"F1 Score for SVM (C=0.8): {f1_svm_1:.2f}\")"
      ],
      "metadata": {
        "id": "fkUjCFA_GOEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2301f877-cacb-4339-9270-0a3e53e8846d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM: 98.34%\n",
            "Precision for SVM (C=0.8): 0.98\n",
            "F1 Score for SVM (C=0.8): 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example 2: Different values for regularization parameter (C)\n",
        "precision_svm_2, f1_svm_2 = calculate_svm_metrics(X_train, y_train, X_val, y_val, C=1.2, degree=3)\n",
        "print(f\"Precision for SVM (C=1.2): {precision_svm_2:.2f}\")\n",
        "print(f\"F1 Score for SVM (C=1.2): {f1_svm_2:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYUIs2yxQ6Ya",
        "outputId": "09542645-1bff-4059-ce6f-926bd7a04986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM: 98.34%\n",
            "Precision for SVM (C=1.2): 0.98\n",
            "F1 Score for SVM (C=1.2): 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Different values for polynomial kernel degree\n",
        "precision_svm_3, f1_svm_3 = calculate_svm_metrics(X_train, y_train, X_val, y_val, C=1.0, degree=2)\n",
        "print(f\"Precision for SVM (degree=2): {precision_svm_3:.2f}\")\n",
        "print(f\"F1 Score for SVM (degree=2): {f1_svm_3:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNb2xpBZQ-GX",
        "outputId": "44469ba1-ed0d-4e81-e647-e4114a01fe6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM: 98.35%\n",
            "Precision for SVM (degree=2): 0.98\n",
            "F1 Score for SVM (degree=2): 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Polynomial Kernel Degree ==> Smoother Decision Boundary ==> May Underfit\n",
        "precision_svm_4, f1_svm_4 = calculate_svm_metrics(X_train, y_train, X_val, y_val, C=1.0, degree=4)\n",
        "print(f\"Precision for SVM (degree=4): {precision_svm_4:.2f}\")\n",
        "print(f\"F1 Score for SVM (degree=4): {f1_svm_4:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlVY0G6Kj8kq",
        "outputId": "3aaadbbb-9e4a-4650-fb28-31715cc84a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM: 98.35%\n",
            "Precision for SVM (degree=4): 0.98\n",
            "F1 Score for SVM (degree=4): 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXZ4j5B-uLTh"
      },
      "source": [
        "# Bayesian Classifier Method"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# What are the parameters of the function?\n",
        "GaussianNB(priors, var_smoothing)\n",
        "\n",
        "\n",
        "1.   priors: sharing initial thoughts or knowledge with the model about how likely each class is before it learns from the data, given to the model in form of array.\n",
        "2.   var_smoothing: Portion of the largest variance of all features that is added to variances for calculation stability, Its default value is 1e-9.\n",
        "\n",
        "\n",
        "# How does var_smoothing affect the accuracy?\n",
        "\n",
        "1.   If there is no variance (all samples in that feature have same value), var_smoothing adds a small value to the variance to prevent division by zero.\n",
        "2.   Increasing var_smoothing value will lead to (maybe) smooth out the model's decision boundaries, reducing overfitting and result in lower accuracy by oversimplifying the relationships between features and classes.\n",
        "3. Decreasing var_smoothing value will lead to (maybe) make the model more sensitive to the training data, resulting in overfitting.\n",
        "\n",
        "\n",
        "**The choice of var_smoothing value should be made carefully, considering the trade-offs between stability, sensitivity to data, and model performance on unseen data.**\n",
        "\n"
      ],
      "metadata": {
        "id": "wqNIA3OHmNhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gaussian_metrics(vs):\n",
        "\n",
        "  # Create a Gausian Bayes Classifier\n",
        "  gnb = GaussianNB(var_smoothing= vs)\n",
        "\n",
        "  # Train the classifier\n",
        "  gnb.fit(X_train, y_train)\n",
        "\n",
        "  # Create predictions on the validation set\n",
        "  predictions = gnb.predict(X_val)\n",
        "\n",
        "  # Evaluate accuracy\n",
        "  accuracy = accuracy_score(y_val, predictions)\n",
        "  print(f\"Accuracy for Gaussian Naive Bayes Classifier: {accuracy * 100:.2f}%\")\n",
        "\n",
        "  # Calculate precision\n",
        "  precision = precision_score(y_val, predictions, average='weighted')\n",
        "\n",
        "  # Calculate F1 score\n",
        "  f1 = f1_score(y_val, predictions, average='weighted')\n",
        "\n",
        "  return precision, f1"
      ],
      "metadata": {
        "id": "n29pEzy2fom5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vs in [1e-5, 1e-6, 1e-7, 1e-8, 1e-9]:\n",
        "  precision_gaussian, f1_gaussian = calculate_gaussian_metrics(vs)\n",
        "  print(f\"Precision for Gaussian Naive Bayes: {precision_gaussian:.2f}\")\n",
        "  print(f\"F1 Score for Gaussian Naive Bayes: {f1_gaussian:.2f}\")\n",
        "  print(\"============================\")"
      ],
      "metadata": {
        "id": "z2LzHNPBfvxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e1ea66-6daa-4597-fe03-bc375683abc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Gaussian Naive Bayes Classifier: 87.88%\n",
            "Precision for Gaussian Naive Bayes: 0.89\n",
            "F1 Score for Gaussian Naive Bayes: 0.88\n",
            "============================\n",
            "Accuracy for Gaussian Naive Bayes Classifier: 86.99%\n",
            "Precision for Gaussian Naive Bayes: 0.88\n",
            "F1 Score for Gaussian Naive Bayes: 0.87\n",
            "============================\n",
            "Accuracy for Gaussian Naive Bayes Classifier: 86.05%\n",
            "Precision for Gaussian Naive Bayes: 0.88\n",
            "F1 Score for Gaussian Naive Bayes: 0.86\n",
            "============================\n",
            "Accuracy for Gaussian Naive Bayes Classifier: 84.87%\n",
            "Precision for Gaussian Naive Bayes: 0.87\n",
            "F1 Score for Gaussian Naive Bayes: 0.85\n",
            "============================\n",
            "Accuracy for Gaussian Naive Bayes Classifier: 83.55%\n",
            "Precision for Gaussian Naive Bayes: 0.86\n",
            "F1 Score for Gaussian Naive Bayes: 0.84\n",
            "============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pds1M-gcuNlD"
      },
      "source": [
        "# Comparison of the three different models using precision, recall, F-Score.."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roaa, add the part where we calculate accuracy for KNN and SVM, this is just precision and F1 score"
      ],
      "metadata": {
        "id": "BwN1UD9CjXt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 1  # best accuracy with k equals 1\n",
        "precision_knn, f1_knn = calculate_knn_metrics(k)\n",
        "print(f\"Precision for KNN: {precision_knn:.2f}\")\n",
        "print(f\"F1 Score for KNN: {f1_knn:.2f}\")\n",
        "print(\"====================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ad6cxyay21E",
        "outputId": "d2a56131-567f-41c2-f012-c1a4c5dc1422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for k=1: 97.82%\n",
            "Precision for KNN: 0.98\n",
            "F1 Score for KNN: 0.98\n",
            "====================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best accuracy for SVM model was C = 1.0, degree = 2\n",
        "precision_svm, f1_svm = calculate_svm_metrics(X_train, y_train, X_val, y_val, C=1.0, degree=2)\n",
        "print(f\"Precision for SVM: {precision_svm:.2f}\")\n",
        "print(f\"F1 Score for SVM: {f1_svm:.2f}\")\n",
        "print(\"====================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P-NX8CbhGva",
        "outputId": "4215c6fa-bceb-4dd2-e2d3-2c8fd35922c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM: 98.35%\n",
            "Precision for SVM: 0.98\n",
            "F1 Score for SVM: 0.98\n",
            "====================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vs = 1e-5 ## this hyperparameter had the best accuracy for this model\n",
        "precision_gaussian, f1_gaussian = calculate_gaussian_metrics(vs)\n",
        "print(f\"Precision for Gaussian Naive Bayes: {precision_gaussian:.2f}\")\n",
        "print(f\"F1 Score for Gaussian Naive Bayes: {f1_gaussian:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POiVafcZhIXP",
        "outputId": "718d0b6e-1cb0-4fe6-b7ad-23fc9ea98704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Gaussian Naive Bayes Classifier: 87.88%\n",
            "Precision for Gaussian Naive Bayes: 0.89\n",
            "F1 Score for Gaussian Naive Bayes: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Old calculation should be deleted\n",
        "# precision_gaussian, f1_gaussian = calculate_gaussian_metrics(X_train, y_train_flat, X_val, y_val_flat)\n",
        "# print(f\"Precision for Gaussian Naive Bayes: {precision_gaussian:.2f}\")\n",
        "# print(f\"F1 Score for Gaussian Naive Bayes: {f1_gaussian:.2f}\")"
      ],
      "metadata": {
        "id": "ESe-BsWMhRR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pi67HXDuC4Z"
      },
      "source": [
        "Important Notes:\n",
        "1. A comment on the results and on the comparison of the three applied models\n",
        "should be given. (As a printed report)\n",
        "2. It is expected that the selected models should be experimented with different\n",
        "hyper-parameters.\n",
        "3. At the final comparison of the results, proper metrics should be selected such\n",
        "as: precision, recall, F1 measure (F-Score), ...\n",
        "4. Error analysis should be stated such as: correctly/wrongly classified\n",
        "examples. Reasons and suggested improvements should also be included."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KOHGOex26g3f"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}